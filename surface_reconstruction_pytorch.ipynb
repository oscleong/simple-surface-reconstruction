{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import ot # optimal transport solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data points, e.g. noisy points on a 2-d plane living in 3-d\n",
    "num_points = 40\n",
    "noise_var = 0.05\n",
    "\n",
    "def sample_plane(num_points, noise_var):\n",
    "    X = torch.empty(num_points, 3).uniform_(0, 2)\n",
    "    X[:,2] = 0\n",
    "    noise = noise_var * torch.randn(num_points, 3)\n",
    "    \n",
    "    return X.double(), noise.double()\n",
    "\n",
    "def sample_sphere(num_points, noise_var):\n",
    "    X = np.random.randn(3, num_points)\n",
    "    X /= np.linalg.norm(X, axis = 0)\n",
    "    X = X.T\n",
    "    X_torch = torch.from_numpy(X)\n",
    "    noise = noise_var * torch.randn(num_points, 3)\n",
    "    \n",
    "    return X_torch.double(), noise.double()\n",
    "\n",
    "def pairwise_distance_matrix(X, Y=None):\n",
    "    '''\n",
    "    Input: x is a Nxd matrix\n",
    "           y is an optional Mxd matirx\n",
    "    Output: dist is a NxM matrix where dist[i,j] is the square norm between x[i,:] and y[j,:]\n",
    "            if y is not given then use 'y=x'.\n",
    "    i.e. dist[i,j] = ||x[i,:]-y[j,:]||^2\n",
    "    '''\n",
    "    X_norm = (X**2).sum(1).view(-1, 1)\n",
    "    if Y is not None:\n",
    "        Y_t = torch.transpose(Y, 0, 1)\n",
    "        Y_norm = (Y**2).sum(1).view(1, -1)\n",
    "    else:\n",
    "        Y_t = torch.transpose(X, 0, 1)\n",
    "        X_norm = X_norm.view(1, -1)\n",
    "    \n",
    "    Dist = X_norm + Y_norm - 2.0 * torch.mm(X, Y_t)\n",
    "    # Ensure diagonal is zero if X=Y\n",
    "    # if Y is None:\n",
    "    #     Dist = Dist - torch.diag(Dist.diag)\n",
    "    return Dist #torch.clamp(Dist, 0.0, np.inf)\n",
    "\n",
    "X, noise = sample_plane(num_points, noise_var)\n",
    "X = X.float()\n",
    "Y = X + noise.float()\n",
    "noise_level = (noise**2).sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build network\n",
    "# num_params = 2*hidden1 + hidden1*3\n",
    "from torchsummary import summary\n",
    "dtype = torch.float\n",
    "device = torch.device('cpu')\n",
    "\n",
    "N = num_points\n",
    "D_in = 2\n",
    "D_out = 3\n",
    "hidden1 = 200\n",
    "hidden2 = 400\n",
    "\n",
    "# Models\n",
    "v1 = torch.randn((N, D_in), device = device, dtype = dtype, requires_grad = True)\n",
    "v2 = torch.randn((N, D_in), device = device, dtype = dtype, requires_grad = True)\n",
    "model1 = torch.nn.Sequential(\n",
    "        torch.nn.Linear(D_in, hidden1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(hidden1, hidden2),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(hidden2, D_out))\n",
    "model2 = torch.nn.Sequential(\n",
    "        torch.nn.Linear(D_in, hidden1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(hidden1, hidden2),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(hidden2, D_out))\n",
    "Y1_pred = model1(v1)\n",
    "Y2_pred = model2(v2)\n",
    "\n",
    "def project_stochastic_to_perm(P):\n",
    "    max_in_rows = np.amax(P, axis = 1)\n",
    "    max_list = [np.where(P == max_in_rows[ii]) for ii in range(P.shape[0])]\n",
    "    for ii in range(len(max_list)):\n",
    "        P[max_list[ii]] = 1\n",
    "    Omega = np.array((P == 1))\n",
    "    return np.multiply(Omega, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization preliminaries:\n",
    "error_train_net1 = []\n",
    "error_test_net1 = []\n",
    "error_train_net2 = []\n",
    "error_test_net2 = []\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction = \"sum\")\n",
    "iteration = 0\n",
    "maxiter = 7500\n",
    "lr = 1e-4\n",
    "lam = 0.01\n",
    "beta = 0 # if beta > 0, then we add a consistency loss when fitting local patches\n",
    "optimizer_w1 = torch.optim.Adam(model1.parameters(), lr)\n",
    "optimizer_w2 = torch.optim.Adam(model2.parameters(), lr)\n",
    "\n",
    "# Get permutation matrices using EMD or sinkhorn\n",
    "C1 = pairwise_distance_matrix(Y1_pred, Y).double()\n",
    "C2 = pairwise_distance_matrix(Y2_pred, Y).double()\n",
    "a = np.ones((num_points,))\n",
    "b = a    \n",
    "C1hat = C1.clone().detach().numpy()\n",
    "C2hat = C2.clone().detach().numpy()\n",
    "# Use EMD\n",
    "P1hat = ot.emd(a, b, C1hat, numItermax=100000, log=False) \n",
    "P2hat = ot.emd(a, b, C2hat, numItermax=100000, log=False)\n",
    "# Or Sinkhorn\n",
    "#P1hat = ot.sinkhorn(a, b, C1hat, lam, method='sinkhorn', numItermax=100000, stopThr=1e-09)\n",
    "#P2hat = ot.sinkhorn(a, b, C2hat, lam, method='sinkhorn', numItermax=100000, stopThr=1e-09)\n",
    "\n",
    "P1hat_inv = np.linalg.inv(P1hat)\n",
    "P2hat_inv = np.linalg.inv(P2hat)\n",
    "\n",
    "P1 = Variable(torch.from_numpy(P1hat), requires_grad=False)\n",
    "P2 = Variable(torch.from_numpy(P2hat), requires_grad=False)\n",
    "\n",
    "# Get permutation pi_p->q between parametric indices\n",
    "P3 = Variable(torch.from_numpy(np.matmul(P1hat, P2hat_inv)), requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting of local patches...\n",
      "Iteration:0, Training loss (net 1):113.0260217487812, Test loss (net 1):113.0058183670044\n",
      "Iteration:0, Training loss (net 2):104.4404502287507, Test loss (net 2):104.35864936560392\n",
      "Noise level:0.26107953667009043\n",
      "Iteration:1000, Training loss (net 1):1.5292652249336243, Test loss (net 1):1.7563410103321075\n",
      "Iteration:1000, Training loss (net 2):0.5306774973869324, Test loss (net 2):0.7402744591236115\n",
      "Noise level:0.26107953667009043\n",
      "Iteration:2000, Training loss (net 1):0.5060577690601349, Test loss (net 1):0.7463847249746323\n",
      "Iteration:2000, Training loss (net 2):0.15006984770298004, Test loss (net 2):0.3817978501319885\n",
      "Noise level:0.26107953667009043\n",
      "Iteration:3000, Training loss (net 1):0.09576818346977234, Test loss (net 1):0.34080635011196136\n",
      "Iteration:3000, Training loss (net 2):0.05297699570655823, Test loss (net 2):0.303362675011158\n",
      "Noise level:0.26107953667009043\n",
      "Iteration:4000, Training loss (net 1):0.022277280688285828, Test loss (net 1):0.2729908376932144\n",
      "Iteration:4000, Training loss (net 2):0.025171980261802673, Test loss (net 2):0.2795719802379608\n",
      "Noise level:0.26107953667009043\n",
      "Iteration:5000, Training loss (net 1):0.002405695617198944, Test loss (net 1):0.2609548941254616\n",
      "Iteration:5000, Training loss (net 2):0.017457827925682068, Test loss (net 2):0.27148962765932083\n",
      "Noise level:0.26107953667009043\n",
      "Iteration:6000, Training loss (net 1):0.0001994892954826355, Test loss (net 1):0.26127270609140396\n",
      "Iteration:6000, Training loss (net 2):0.01134483516216278, Test loss (net 2):0.2671232670545578\n",
      "Noise level:0.26107953667009043\n",
      "Iteration:7000, Training loss (net 1):0.0003415718674659729, Test loss (net 1):0.2615901455283165\n",
      "Iteration:7000, Training loss (net 2):0.0061044394969940186, Test loss (net 2):0.2646392732858658\n",
      "Noise level:0.26107953667009043\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Step 1: fit local patches to the surface\n",
    "print(\"Fitting of local patches...\")\n",
    "while iteration < maxiter:\n",
    "        \n",
    "    # Prediction & pairwise distance matrices \n",
    "    Y1_pred = model1(v1)\n",
    "    Y2_pred = model2(v2)\n",
    "    C1 = pairwise_distance_matrix(Y1_pred, Y).double()\n",
    "    C2 = pairwise_distance_matrix(Y2_pred, Y).double()\n",
    "    C1x = pairwise_distance_matrix(Y1_pred, X).double()\n",
    "    C2x = pairwise_distance_matrix(Y2_pred, X).double()\n",
    "    \n",
    "    # Losses\n",
    "    # Train loss\n",
    "    train_loss_net1 = torch.mul(P1, C1).sum().sum()\n",
    "    train_loss_net2 = torch.mul(P2, C2).sum().sum()\n",
    "    if beta > 0:\n",
    "        C3 = pairwise_distance_matrix(Y1_pred, Y2_pred).double()\n",
    "        train_consistency = torch.mul(P3, C3).sum().sum()\n",
    "        total_train_loss = train_loss_net1 + train_loss_net2 + beta*train_consistency\n",
    "    else:\n",
    "        total_train_loss = train_loss_net1 + train_loss_net2\n",
    "    \n",
    "    # Test loss\n",
    "    test_loss_net1 = torch.mul(P1, C1x).sum().sum() \n",
    "    test_loss_net2 = torch.mul(P2, C2x).sum().sum()    \n",
    "        \n",
    "    # Optimization\n",
    "    optimizer_w1.zero_grad()\n",
    "    optimizer_w2.zero_grad()\n",
    "    total_train_loss.backward()\n",
    "    optimizer_w1.step()\n",
    "    optimizer_w2.step()\n",
    "        \n",
    "    if iteration % 500 == 0:\n",
    "        print(\"Iteration:\" + str(iteration) \n",
    "                  + \", Training loss (net 1):\" + str(train_loss_net1.item()) \n",
    "                  + \", Test loss (net 1):\" + str(test_loss_net1.item()))\n",
    "        print(\"Iteration:\" + str(iteration) \n",
    "                  + \", Training loss (net 2):\" + str(train_loss_net2.item()) \n",
    "                  + \", Test loss (net 2):\" + str(test_loss_net2.item()))\n",
    "        print(\"Noise level:\" + str(noise_level.item()))\n",
    "\n",
    "    error_train_net1.append(train_loss_net1.item())\n",
    "    error_train_net2.append(train_loss_net2.item())\n",
    "    error_test_net1.append(test_loss_net1.item())\n",
    "    error_test_net2.append(test_loss_net2.item())\n",
    "    \n",
    "    iteration += 1\n",
    "print('--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency fitting...\n",
      "Iteration:0, Training loss (net 1):2.9437243938446045e-05, Test loss (net 1):0.26082464307546616\n",
      "Iteration:0, Training loss (net 2):0.004461146891117096, Test loss (net 2):0.26425738632678986\n",
      "Iteration:0, Consistency loss:0.004528149962425232\n",
      "Noise level:0.26107953667009043\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Ensure that the output of the networks is consistent with one another\n",
    "print(\"Consistency fitting...\")\n",
    "consistency_loss = []\n",
    "iteration = 0\n",
    "if beta > 0:\n",
    "    maxiter = 0\n",
    "else:\n",
    "    maxiter = 1000\n",
    "\n",
    "while iteration < maxiter:\n",
    "    \n",
    "    # Prediction & pairwise distance matrices\n",
    "    Y1_pred = model1(v1)\n",
    "    Y2_pred = model2(v2)\n",
    "    C1 = pairwise_distance_matrix(Y1_pred, Y).double()\n",
    "    C2 = pairwise_distance_matrix(Y2_pred, Y).double()    \n",
    "    C3 = pairwise_distance_matrix(Y1_pred, Y2_pred).double()\n",
    "    C1x = pairwise_distance_matrix(Y1_pred, X).double()\n",
    "    C2x = pairwise_distance_matrix(Y2_pred, X).double()   \n",
    "            \n",
    "    # Losses\n",
    "    train_loss_net1 = torch.mul(P1, C1).sum().sum()\n",
    "    train_loss_net2 = torch.mul(P2, C2).sum().sum()\n",
    "    train_consistency = torch.mul(P3, C3).sum().sum()\n",
    "    test_loss_net1 = torch.mul(P1, C1x).sum().sum() \n",
    "    test_loss_net2 = torch.mul(P2, C2x).sum().sum()  \n",
    "    \n",
    "    # Optimization\n",
    "    optimizer_w1.zero_grad()\n",
    "    optimizer_w2.zero_grad()\n",
    "    train_consistency.backward()\n",
    "    optimizer_w1.step()\n",
    "    optimizer_w2.step()\n",
    "    \n",
    "    if iteration % 500 == 0:\n",
    "        print(\"Iteration:\" + str(iteration) + \", Training loss (net 1):\" + str(train_loss_net1.item())\n",
    "              + \", Test loss (net 1):\" + str(test_loss_net1.item()))\n",
    "        print(\"Iteration:\" + str(iteration) + \", Training loss (net 2):\" + str(train_loss_net2.item())\n",
    "              + \", Test loss (net 2):\" + str(test_loss_net2.item()))\n",
    "        print(\"Iteration:\" + str(iteration) + \", Consistency loss:\" + str(train_consistency.item()))    \n",
    "        print(\"Noise level:\" + str(noise_level.item()))\n",
    "        \n",
    "    error_train_net1.append(train_loss_net1.item())\n",
    "    error_train_net2.append(train_loss_net2.item())    \n",
    "    error_test_net1.append(test_loss_net1.item())\n",
    "    error_test_net2.append(test_loss_net2.item())\n",
    "    \n",
    "    iteration += 1\n",
    "print('--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583d5a16dd104ec684f378d7dd41d8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b791b03fa9c47de8620223514e6ccd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b0c60a10a54ee4be7d91a1e92587a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ad41d296d8>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "Yhat1 = Y1_pred.detach().numpy()\n",
    "Yhat2 = Y2_pred.detach().numpy()\n",
    "#yt_limit = noise_level + 1e-2\n",
    "#yb_limit = max(noise_level - 1e-2, 1e-6)\n",
    "\n",
    "# Plot all losses(training and test)\n",
    "plt.figure(1)\n",
    "plt.plot(error_train_net1, color='b', linestyle='-', label='Train Loss (net 1)')\n",
    "plt.plot(error_test_net1, color='b', linestyle='--', label='Test Loss (net 1)')\n",
    "plt.plot(error_train_net2, color='r', linestyle='-', label='Train Loss (net 2)')\n",
    "plt.plot(error_test_net2, color='r', linestyle='--',  label='Test Loss (net 2)')\n",
    "plt.axhline(y=noise_level, color='m', linestyle='-.', label='noise level')\n",
    "plt.ylabel('l2 loss')\n",
    "plt.xlabel('number of iterations')\n",
    "plt.yscale('log')\n",
    "plt.title('Comparison of losses for each net over time')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot data points\n",
    "fig, ax = plt.subplots(1, 1, subplot_kw={'projection':'3d', 'aspect':'equal'})\n",
    "ax.scatter(Y[:100,0], Y[:100,1], Y[:100,2], s=30, c='b', zorder=10, label='noisy points')\n",
    "ax.scatter(X[:100,0], X[:100,1], X[:100,2], s=30, c='r', zorder=10, label='clean points')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot reconstructed points\n",
    "fig, ax = plt.subplots(1, 1, subplot_kw={'projection':'3d', 'aspect':'equal'})\n",
    "ax.scatter(Yhat1[:100,0], Yhat1[:100,1], Yhat1[:100,2], s=30, c='b', zorder=10, label = 'recovered pts 1')\n",
    "ax.scatter(Yhat2[:100,0], Yhat2[:100,1], Yhat2[:100,2], s=30, c='r', zorder=10, label = 'recovered pts 2')\n",
    "ax.scatter(Y[:100,0], Y[:100,1], Y[:100,2], s = 30, c = 'g', zorder = 10, label = 'noisy pts')\n",
    "ax.scatter(X[:100,0], X[:100,1], X[:100,2], s = 30, c = 'k', zorder = 10, label = 'clean pts')\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
